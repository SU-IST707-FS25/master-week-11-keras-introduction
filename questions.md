1. What are the main components (parameters) associated with a perceptron? What does this remind you of?
2. Describe the architecture of a multi-layer perceptron.
3. What is a loss function?  Can you provide an example of a loss function?
4. What is backpropagation?
5. Why are activation functions important?
6. Name 3 different activation functions.
7. What is the "vanishing gradient" problem? When is it likely to occur?
8. What is a tensor?
9. What is a "batch" when training a network?
10. What is the point of using a batch?
11. What is the size of a batch in stochastic gradient decent?
12. What is an epoch?
13. What happens if you use too few epochs?  Too many?
14. What is the "sequential API" in Keras?



